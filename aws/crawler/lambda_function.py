"""
AWS Lambdaå‡½æ•¸ - æ–°èçˆ¬èŸ²
è² è²¬ï¼šå®šæ™‚çˆ¬å–Yahoo Financeæ–°èä¸¦å­˜å…¥Supabase
"""
import json
import os
import sys
from pathlib import Path

# è¨­ç½®ç·¨ç¢¼ï¼ˆWindowsæœ¬åœ°æ¸¬è©¦éœ€è¦ï¼‰
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent.parent))

from core.database import db_manager
from scraper.scraper import NewsScraperManager
from core.utils import get_current_taiwan_time

def lambda_handler(event, context):
    """Lambdaä¸»å…¥å£å‡½æ•¸"""
    
    print("ğŸš€ AWS Lambda æ–°èçˆ¬èŸ²é–‹å§‹åŸ·è¡Œ")
    taiwan_time = get_current_taiwan_time()
    print(f"ğŸ• åŸ·è¡Œæ™‚é–“: {taiwan_time.strftime('%Y-%m-%d %H:%M:%S')} (å°ç£æ™‚é–“)")
    
    try:
        # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
        required_vars = ['SUPABASE_URL', 'SUPABASE_SERVICE_KEY', 'OPENAI_API_KEY']
        for var in required_vars:
            if not os.environ.get(var):
                raise ValueError(f"ç¼ºå°‘ç’°å¢ƒè®Šæ•¸: {var}")
        
        # åˆå§‹åŒ–çˆ¬èŸ²
        scraper = NewsScraperManager()
        
        # çˆ¬å–æ–°èï¼ˆAWSç’°å¢ƒé™åˆ¶è™•ç†æ•¸é‡ï¼‰
        limit = int(os.environ.get('CRAWLER_LIMIT', '10'))
        print(f"ğŸ“° é–‹å§‹çˆ¬å–æ–°èï¼Œé™åˆ¶ {limit} ç¯‡")
        
        # ç²å–æ–°èåˆ—è¡¨
        news_list = scraper.scrape_yahoo_finance_list()
        if not news_list:
            return {
                'statusCode': 500,
                'body': json.dumps({'error': 'ç„¡æ³•ç²å–æ–°èåˆ—è¡¨'})
            }
        
        # è™•ç†æ–‡ç« 
        articles = []
        success_count = 0
        
        for i, news_item in enumerate(news_list[:limit]):
            # æª¢æŸ¥æ˜¯å¦å·²è™•ç†
            if db_manager.is_article_processed(news_item['link']):
                continue
            
            print(f"ğŸ”„ è™•ç†æ–‡ç«  {i+1}/{limit}: {news_item['title'][:50]}...")
            
            # çˆ¬å–æ–‡ç« å…§å®¹
            content = scraper.scrape_article_content(news_item['link'])
            if not content:
                continue
            
            # ç”Ÿæˆæ‘˜è¦
            from core.utils import generate_summary_optimized
            summary = generate_summary_optimized(content)
            
            # æ§‹å»ºæ–‡ç« æ•¸æ“š
            article_data = {
                'original_url': news_item['link'],
                'source': 'yahoo_finance',
                'title': news_item['title'],
                'summary': summary,
                'published_at': taiwan_time.isoformat()
            }
            
            # ä¿å­˜åˆ°è³‡æ–™åº«
            article_id = db_manager.save_new_article(article_data)
            if article_id:
                articles.append(article_data)
                success_count += 1
                print(f"âœ… æ–‡ç« è™•ç†æˆåŠŸ")
            else:
                print(f"âŒ æ–‡ç« ä¿å­˜å¤±æ•—")
        
        print(f"ğŸ‰ çˆ¬èŸ²ä»»å‹™å®Œæˆï¼æˆåŠŸè™•ç† {success_count} ç¯‡æ–‡ç« ")
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': f'æˆåŠŸè™•ç† {success_count} ç¯‡æ–‡ç« ',
                'articles_count': success_count,
                'execution_time': taiwan_time.isoformat()
            })
        }
        
    except Exception as e:
        print(f"âŒ çˆ¬èŸ²åŸ·è¡Œå¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e),
                'execution_time': taiwan_time.isoformat()
            })
        }