"""
AWS Lambdaå‡½æ•¸ - ç°¡åŒ–ç‰ˆæ–°èçˆ¬èŸ²
ç§»é™¤Supabaseä¾è³´ï¼Œç›´æ¥è¼¸å‡ºçµæœç”¨æ–¼æ¸¬è©¦
"""
import json
import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import pytz

def get_current_taiwan_time():
    """ç²å–å°ç£æ™‚é–“"""
    taiwan_tz = pytz.timezone('Asia/Taipei') 
    return datetime.now(taiwan_tz)

def scrape_yahoo_finance_news():
    """ç°¡åŒ–ç‰ˆæ–°èçˆ¬èŸ²"""
    try:
        url = "https://finance.yahoo.com/topic/stock-market-news"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=30)
        if response.status_code != 200:
            return []
            
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # å°‹æ‰¾æ–°èæ–‡ç« 
        articles = []
        news_items = soup.find_all('h3', class_='clamp')[:5]  # é™åˆ¶5ç¯‡
        
        for item in news_items:
            link_elem = item.find('a')
            if link_elem:
                title = link_elem.get_text(strip=True)
                link = link_elem.get('href', '')
                if link and not link.startswith('http'):
                    link = 'https://finance.yahoo.com' + link
                
                articles.append({
                    'title': title,
                    'link': link
                })
        
        return articles
        
    except Exception as e:
        print(f"çˆ¬èŸ²éŒ¯èª¤: {str(e)}")
        return []

def generate_simple_summary(title):
    """ç°¡åŒ–ç‰ˆæ‘˜è¦ç”Ÿæˆ"""
    try:
        # å¦‚æœæ²’æœ‰OpenAI APIï¼Œè¿”å›æ¨™é¡Œ
        api_key = os.environ.get('OPENAI_API_KEY')
        if not api_key:
            return f"æ‘˜è¦ï¼š{title}"
            
        # é€™è£¡å¯ä»¥åŠ å…¥OpenAI APIèª¿ç”¨
        return f"AIæ‘˜è¦ï¼š{title}"
        
    except Exception as e:
        return f"æ‘˜è¦ç”Ÿæˆå¤±æ•—ï¼š{title}"

def lambda_handler(event, context):
    """Lambdaä¸»å…¥å£å‡½æ•¸"""
    
    print("ğŸš€ AWS Lambda ç°¡åŒ–ç‰ˆæ–°èçˆ¬èŸ²é–‹å§‹åŸ·è¡Œ")
    taiwan_time = get_current_taiwan_time()
    print(f"ğŸ• åŸ·è¡Œæ™‚é–“: {taiwan_time.strftime('%Y-%m-%d %H:%M:%S')} (å°ç£æ™‚é–“)")
    
    try:
        # çˆ¬å–æ–°è
        print("ğŸ“° é–‹å§‹çˆ¬å–Yahoo Financeæ–°è...")
        articles = scrape_yahoo_finance_news()
        
        if not articles:
            return {
                'statusCode': 500,
                'body': json.dumps({'error': 'ç„¡æ³•ç²å–æ–°èåˆ—è¡¨'}, ensure_ascii=False)
            }
        
        # è™•ç†æ–‡ç« 
        processed_articles = []
        for i, article in enumerate(articles):
            print(f"ğŸ”„ è™•ç†æ–‡ç«  {i+1}: {article['title'][:50]}...")
            
            summary = generate_simple_summary(article['title'])
            
            processed_article = {
                'title': article['title'],
                'link': article['link'],
                'summary': summary,
                'processed_at': taiwan_time.isoformat()
            }
            
            processed_articles.append(processed_article)
        
        print(f"ğŸ‰ çˆ¬èŸ²ä»»å‹™å®Œæˆï¼æˆåŠŸè™•ç† {len(processed_articles)} ç¯‡æ–‡ç« ")
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': f'æˆåŠŸè™•ç† {len(processed_articles)} ç¯‡æ–‡ç« ',
                'articles': processed_articles,
                'execution_time': taiwan_time.isoformat()
            }, ensure_ascii=False)
        }
        
    except Exception as e:
        print(f"âŒ çˆ¬èŸ²åŸ·è¡Œå¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e),
                'execution_time': taiwan_time.isoformat()
            }, ensure_ascii=False)
        }