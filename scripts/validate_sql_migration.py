#!/usr/bin/env python3
"""
SQLé·ç§»è…³æœ¬é©—è­‰å™¨
æª¢æŸ¥ä¿®å¾©å¾Œçš„SQLèªæ³•å’Œçµæ§‹æ­£ç¢ºæ€§
"""

import re
from pathlib import Path

def validate_sql_syntax():
    """é©—è­‰SQLèªæ³•çµæ§‹"""
    sql_file = Path(__file__).parent.parent / "database" / "unified_tag_migration.sql"
    
    if not sql_file.exists():
        print("âŒ SQLæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    with open(sql_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    print("ğŸ” é©—è­‰SQLè…³æœ¬èªæ³•...")
    
    # æª¢æŸ¥1: ç¢ºä¿æ²’æœ‰å•é¡Œçš„CROSS JOINèªæ³•
    cross_join_on_pattern = r'CROSS\s+JOIN.*?\)\s+kw\s+ON\s+t\.tag_code\s*='
    if re.search(cross_join_on_pattern, content, re.IGNORECASE | re.DOTALL):
        print("âŒ ç™¼ç¾å•é¡Œçš„CROSS JOIN ONèªæ³•")
        return False
    else:
        print("âœ… æ²’æœ‰ç™¼ç¾å•é¡Œçš„CROSS JOINèªæ³•")
    
    # æª¢æŸ¥2: ç¢ºä¿æ¯å€‹INSERTéƒ½æœ‰æ­£ç¢ºçš„çµæ§‹
    insert_pattern = r'INSERT\s+INTO\s+public\.keyword_mappings.*?FROM.*?CROSS\s+JOIN.*?ON\s+CONFLICT'
    insert_matches = re.findall(insert_pattern, content, re.IGNORECASE | re.DOTALL)
    
    expected_insert_count = 20  # 20å€‹æ¨™ç±¤ï¼Œæ¯å€‹æ¨™ç±¤ä¸€å€‹INSERT
    if len(insert_matches) != expected_insert_count:
        print(f"âš ï¸ INSERTèªå¥æ•¸é‡: {len(insert_matches)} (é æœŸ: {expected_insert_count})")
    else:
        print(f"âœ… INSERTèªå¥æ•¸é‡æ­£ç¢º: {len(insert_matches)}")
    
    # æª¢æŸ¥3: ç¢ºä¿æ‰€æœ‰æ¨™ç±¤éƒ½æœ‰å°æ‡‰çš„INSERT
    expected_tags = [
        'APPLE', 'TSMC', 'TESLA', 'AI_TECH', 'TECH', 'ELECTRIC_VEHICLES',
        'STOCK_MARKET', 'ECONOMIES', 'FEDERAL_RESERVE', 'EARNINGS', 'CRYPTO',
        'HOUSING', 'ENERGY', 'HEALTHCARE', 'FINANCE', 'TARIFFS', 'TRADE',
        'BONDS', 'COMMODITIES', 'LATEST'
    ]
    
    missing_tags = []
    for tag in expected_tags:
        if f"tag_code = '{tag}'" not in content:
            missing_tags.append(tag)
    
    if missing_tags:
        print(f"âŒ ç¼ºå°‘æ¨™ç±¤çš„INSERT: {missing_tags}")
        return False
    else:
        print("âœ… æ‰€æœ‰æ¨™ç±¤éƒ½æœ‰å°æ‡‰çš„INSERTèªå¥")
    
    # æª¢æŸ¥4: ç¢ºä¿ON CONFLICTèªæ³•æ­£ç¢º
    conflict_pattern = r'ON\s+CONFLICT\s*\(\s*tag_id\s*,\s*keyword\s*\)\s+DO\s+UPDATE\s+SET'
    conflict_matches = re.findall(conflict_pattern, content, re.IGNORECASE)
    
    if len(conflict_matches) != expected_insert_count:
        print(f"âš ï¸ ON CONFLICTèªå¥æ•¸é‡: {len(conflict_matches)} (é æœŸ: {expected_insert_count})")
    else:
        print(f"âœ… ON CONFLICTèªå¥æ•¸é‡æ­£ç¢º: {len(conflict_matches)}")
    
    # æª¢æŸ¥5: ç¢ºä¿VALUESèªæ³•æ­£ç¢º
    values_pattern = r'VALUES\s*\(\s*\([^)]+\)[^)]*\)\s*AS\s+kw\s*\(\s*keyword\s*,\s*language\s*,\s*confidence\s*\)'
    values_matches = re.findall(values_pattern, content, re.IGNORECASE | re.DOTALL)
    
    if len(values_matches) != expected_insert_count:
        print(f"âš ï¸ VALUESèªå¥æ•¸é‡: {len(values_matches)} (é æœŸ: {expected_insert_count})")
    else:
        print(f"âœ… VALUESèªå¥æ ¼å¼æ­£ç¢º: {len(values_matches)}")
    
    return True

def count_keywords():
    """çµ±è¨ˆé—œéµå­—æ•¸é‡"""
    sql_file = Path(__file__).parent.parent / "database" / "unified_tag_migration.sql"
    
    with open(sql_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # çµ±è¨ˆä¸­è‹±æ–‡é—œéµå­—
    zh_keywords = len(re.findall(r"'[^']*[\u4e00-\u9fff]+[^']*'", content))
    en_keywords = len(re.findall(r"'[a-zA-Z][^']*', 'en'", content))
    
    print(f"\nğŸ“Š é—œéµå­—çµ±è¨ˆ:")
    print(f"   ä¸­æ–‡é—œéµå­—: {zh_keywords} å€‹")
    print(f"   è‹±æ–‡é—œéµå­—: {en_keywords} å€‹")
    print(f"   ç¸½è¨ˆ: {zh_keywords + en_keywords} å€‹")
    
    return zh_keywords + en_keywords

def validate_structure():
    """é©—è­‰è…³æœ¬æ•´é«”çµæ§‹"""
    sql_file = Path(__file__).parent.parent / "database" / "unified_tag_migration.sql"
    
    with open(sql_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    print("\nğŸ—ï¸ é©—è­‰è…³æœ¬çµæ§‹...")
    
    # æª¢æŸ¥å¿…è¦çš„å€æ®µ
    required_sections = [
        "ç¬¬ä¸€éšæ®µ: åŸºç¤æ¨™ç±¤æ•¸æ“šé·ç§»",
        "ç¬¬äºŒéšæ®µ: é—œéµå­—æ˜ å°„æ•¸æ“šé·ç§»", 
        "ç¬¬ä¸‰éšæ®µ: å»ºç«‹ç´¢å¼•ä»¥å„ªåŒ–æŸ¥è©¢æ€§èƒ½",
        "ç¬¬å››éšæ®µ: å‰µå»ºçµ±è¨ˆè¦–åœ–",
        "ç¬¬äº”éšæ®µ: æ¬Šé™è¨­ç½®"
    ]
    
    for section in required_sections:
        if section in content:
            print(f"âœ… æ‰¾åˆ°å€æ®µ: {section}")
        else:
            print(f"âŒ ç¼ºå°‘å€æ®µ: {section}")
    
    # æª¢æŸ¥ç´¢å¼•å‰µå»º
    index_count = len(re.findall(r'CREATE\s+INDEX', content, re.IGNORECASE))
    print(f"âœ… ç´¢å¼•å‰µå»ºèªå¥: {index_count} å€‹")
    
    # æª¢æŸ¥è¦–åœ–å‰µå»º
    view_count = len(re.findall(r'CREATE.*VIEW', content, re.IGNORECASE))
    print(f"âœ… è¦–åœ–å‰µå»ºèªå¥: {view_count} å€‹")
    
    return True

def main():
    """ä¸»é©—è­‰å‡½æ•¸"""
    print("ğŸ”§ SQLé·ç§»è…³æœ¬é©—è­‰å™¨")
    print("=" * 50)
    
    # èªæ³•é©—è­‰
    if not validate_sql_syntax():
        print("\nâŒ SQLèªæ³•é©—è­‰å¤±æ•—")
        return 1
    
    # é—œéµå­—çµ±è¨ˆ
    keyword_count = count_keywords()
    
    # çµæ§‹é©—è­‰
    if not validate_structure():
        print("\nâŒ çµæ§‹é©—è­‰å¤±æ•—")
        return 1
    
    print(f"\nğŸ‰ é©—è­‰å®Œæˆï¼")
    print(f"âœ… SQLèªæ³•æ­£ç¢º")
    print(f"âœ… åŒ…å«20å€‹æ¨™ç±¤INSERTèªå¥")
    print(f"âœ… åŒ…å«{keyword_count}å€‹é—œéµå­—æ˜ å°„")
    print(f"âœ… çµæ§‹å®Œæ•´ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦å€æ®µ")
    
    print(f"\nğŸ“‹ ä½¿ç”¨èªªæ˜:")
    print(f"1. åœ¨Supabase SQLç·¨è¼¯å™¨ä¸­åŸ·è¡Œ: database/unified_tag_migration.sql")
    print(f"2. åŸ·è¡Œæ¸¬è©¦: python scripts/dynamic_tags.py")
    print(f"3. é©—è­‰æ¨é€: python scripts/run_pusher_test.py")
    
    return 0

if __name__ == "__main__":
    exit(main())